{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518d435c-956e-4cf9-8cda-8cc081c314ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== IMPORTS ====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_dir = \"/home/77462217B/lois/ADMeth/model/gridsearchmodelwomasklight22K\"\n",
    "datasets = [\n",
    "    \"/home/77462217B/lois/ADMeth/data/ValidateDataset5K_float16.npy\",\n",
    "    \"/home/77462217B/lois/ADMeth/data/datasets/Michaud_float16.npy\",\n",
    "    \"/home/77462217B/lois/ADMeth/data/datasets/FraCon_float16.npy\",\n",
    "    \"/home/77462217B/lois/ADMeth/data/datasets/FraCas_float16.npy\"\n",
    "]\n",
    "\n",
    "output_base_dir = \"/home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6260e4-e053-4dbd-ac65-f4fb72470269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info_path = os.path.join(model_dir, \"model_info.txt\")\n",
    "if not os.path.exists(info_path):\n",
    "    raise FileNotFoundError(f\"No se encontró model_info.txt en {model_dir}\")\n",
    "\n",
    "with open(info_path, \"r\") as f:\n",
    "    info_lines = [line.rstrip(\"\\n\") for line in f.readlines()]\n",
    "\n",
    "info_kv = {}\n",
    "for line in info_lines:\n",
    "    if \":\" in line:\n",
    "        key, value = line.split(\":\", 1)\n",
    "        info_kv[key.strip()] = value.strip()\n",
    "\n",
    "if \"Hidden neurons\" in info_kv:\n",
    "    hidden_neurons = int(re.search(r\"\\d+\", info_kv[\"Hidden neurons\"]).group())\n",
    "else:\n",
    "    raise KeyError(\"Falta 'Hidden neurons' en model_info.txt\")\n",
    "\n",
    "# Latent dim\n",
    "if \"Latent dimensions\" in info_kv:\n",
    "    latent_dim = int(re.search(r\"\\d+\", info_kv[\"Latent dimensions\"]).group())\n",
    "else:\n",
    "    raise KeyError(\"Falta 'Latent dim' en model_info.txt\")\n",
    "\n",
    "# BatchNorm\n",
    "if \"BatchNorm\" in info_kv:\n",
    "    use_batchnorm = info_kv[\"BatchNorm\"].strip().lower().startswith(\"t\")\n",
    "else:\n",
    "    use_batchnorm = True\n",
    "\n",
    "dropout_line = info_kv.get(\"Dropout\", \"False\")\n",
    "m_bool = re.search(r\"(True|False)\", dropout_line, re.IGNORECASE)\n",
    "use_dropout = (m_bool.group(1).lower() == \"true\") if m_bool else False\n",
    "\n",
    "m_rate = re.search(r\"rate\\s*=\\s*([0-9]*\\.?[0-9]+)\", dropout_line)\n",
    "dropout_rate = float(m_rate.group(1)) if m_rate else (0.0 if not use_dropout else 0.2)\n",
    "\n",
    "segment_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3095a2fa-1306-49f0-b547-c8900472a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración leída del modelo: Hidden=1000, Latent=100, Dropout=True (rate=0.2), BatchNorm=True, Segment size=10000\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Configuración leída del modelo: Hidden={hidden_neurons}, Latent={latent_dim}, \"\n",
    "    f\"Dropout={use_dropout} (rate={dropout_rate}), BatchNorm={use_batchnorm}, Segment size={segment_size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1209f6d-022b-4066-8ef3-a724096cc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_neurons: int, latent_size: int,\n",
    "                 use_dropout: bool, dropout_rate: float, use_batchnorm: bool):\n",
    "        super().__init__()\n",
    "        enc = [nn.Linear(input_size, hidden_neurons), nn.ReLU()]\n",
    "        if use_batchnorm:\n",
    "            enc.append(nn.BatchNorm1d(hidden_neurons))\n",
    "        if use_dropout and dropout_rate > 0:\n",
    "            enc.append(nn.Dropout(dropout_rate))\n",
    "        enc += [nn.Linear(hidden_neurons, latent_size), nn.ReLU()]\n",
    "        if use_batchnorm:\n",
    "            enc.append(nn.BatchNorm1d(latent_size))\n",
    "        if use_dropout and dropout_rate > 0:\n",
    "            enc.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        dec = [nn.Linear(latent_size, hidden_neurons), nn.ReLU()]\n",
    "        if use_batchnorm:\n",
    "            dec.append(nn.BatchNorm1d(hidden_neurons))\n",
    "        if use_dropout and dropout_rate > 0:\n",
    "            dec.append(nn.Dropout(dropout_rate))\n",
    "        # Usa Identity() si tus datos no están en [0,1]\n",
    "        dec += [nn.Linear(hidden_neurons, input_size), nn.Sigmoid()]\n",
    "\n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b615f84c-2312-4cc8-bd7d-34eb0728db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 32 modelos de segmentos.\n"
     ]
    }
   ],
   "source": [
    "model_files = sorted(\n",
    "    [f for f in os.listdir(model_dir) if f.startswith(\"autoencoder_segment_\") and f.endswith(\".pth\")],\n",
    "    key=lambda x: int(re.search(r\"_(\\d+)\\.pth\", x).group(1))\n",
    ")\n",
    "\n",
    "num_segments = len(model_files)\n",
    "print(f\"{num_segments} segment models found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202340d7-72c5-42a4-b4a4-17a5518f6f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Evaluando dataset: ValidateDataset5K_float16\n",
      "✅ MSE global: 0.002863\n",
      "✅ MAE: 0.028679 | RMSE: 0.053507 | Mediana AE: 0.015325 | P95 AE: 0.097734\n",
      "✅ Missing: 1.14%\n",
      "Guardado plot: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/ValidateDataset5K_float16/ValidateDataset5K_float16_abs_error_hist.png\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/ValidateDataset5K_float16/ValidateDataset5K_float16_mse_per_sample_per_position.npy\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/ValidateDataset5K_float16/ValidateDataset5K_float16_mse_summary.csv\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/ValidateDataset5K_float16/model_info.txt\n",
      "\n",
      "→ Evaluando dataset: Michaud_float16\n",
      "✅ MSE global: 0.002977\n",
      "✅ MAE: 0.037652 | RMSE: 0.054559 | Mediana AE: 0.026502 | P95 AE: 0.109375\n",
      "✅ Missing: 3.82%\n",
      "Guardado plot: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/Michaud_float16/Michaud_float16_abs_error_hist.png\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/Michaud_float16/Michaud_float16_mse_per_sample_per_position.npy\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/Michaud_float16/Michaud_float16_mse_summary.csv\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/Michaud_float16/model_info.txt\n",
      "\n",
      "→ Evaluando dataset: FraCon_float16\n",
      "✅ MSE global: 0.001838\n",
      "✅ MAE: 0.029778 | RMSE: 0.042868 | Mediana AE: 0.021562 | P95 AE: 0.084234\n",
      "✅ Missing: 4.85%\n",
      "Guardado plot: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCon_float16/FraCon_float16_abs_error_hist.png\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCon_float16/FraCon_float16_mse_per_sample_per_position.npy\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCon_float16/FraCon_float16_mse_summary.csv\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCon_float16/model_info.txt\n",
      "\n",
      "→ Evaluando dataset: FraCas_float16\n",
      "✅ MSE global: 0.001980\n",
      "✅ MAE: 0.028986 | RMSE: 0.044497 | Mediana AE: 0.019193 | P95 AE: 0.089844\n",
      "✅ Missing: 0.26%\n",
      "Guardado plot: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCas_float16/FraCas_float16_abs_error_hist.png\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCas_float16/FraCas_float16_mse_per_sample_per_position.npy\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCas_float16/FraCas_float16_mse_summary.csv\n",
      "Guardado: /home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/FraCas_float16/model_info.txt\n"
     ]
    }
   ],
   "source": [
    "for dataset_path in datasets:\n",
    "    dataset_name = os.path.splitext(os.path.basename(dataset_path))[0]\n",
    "\n",
    "    dataset_output_dir = os.path.join(output_base_dir, dataset_name)\n",
    "    os.makedirs(dataset_output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n→ Evaluating dataset: {dataset_name}\")\n",
    "    X_data = np.load(dataset_path).astype(np.float16).T  # (n_samples, total_features)\n",
    "    n_samples, total_features = X_data.shape\n",
    "    expected_features = 320000\n",
    "    assert total_features == expected_features, f\"{dataset_path} has {total_features} columns, {expected_features} expected\"\n",
    "\n",
    "    mse_matrix = np.zeros((n_samples, total_features), dtype=np.float16)\n",
    "    segment_mse_avgs = []\n",
    "\n",
    "    for idx, model_file in enumerate(model_files):\n",
    "        start = idx * segment_size\n",
    "        end = start + segment_size\n",
    "        X_segment = X_data[:, start:end]  \n",
    "\n",
    "        model = SegmentAutoencoder(\n",
    "            input_size=segment_size,\n",
    "            hidden_neurons=hidden_neurons,\n",
    "            latent_size=latent_dim,\n",
    "            use_dropout=use_dropout,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_batchnorm=use_batchnorm\n",
    "        ).to(device)\n",
    "\n",
    "        state = torch.load(os.path.join(model_dir, model_file), map_location=device)\n",
    "        if isinstance(state, dict) and \"state_dict\" in state:\n",
    "            state = state[\"state_dict\"]\n",
    "        if isinstance(state, dict) and any(k.startswith(\"module.\") for k in state.keys()):\n",
    "            state = {k.replace(\"module.\", \"\", 1): v for k, v in state.items()}\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_segment, device=device, dtype=torch.float32)\n",
    "            preds = model(X_tensor).cpu().numpy().astype(np.float16)\n",
    "\n",
    "        X_seg32 = X_segment.astype(np.float32)\n",
    "        mse_per_position = (preds - X_seg32) ** 2\n",
    "\n",
    "        missing_mask = (X_segment == 0)\n",
    "        mse_per_position[missing_mask] = -1.0\n",
    "\n",
    "        mse_matrix[:, start:end] = mse_per_position.astype(np.float16)\n",
    "\n",
    "        valid_mask = ~missing_mask\n",
    "        if np.any(valid_mask):\n",
    "            seg_mean = mse_per_position[valid_mask].mean()\n",
    "        else:\n",
    "            seg_mean = np.nan\n",
    "        segment_mse_avgs.append(seg_mean)\n",
    "\n",
    "    missing_mask_all = (mse_matrix == -1)\n",
    "    total_entries = mse_matrix.size\n",
    "    num_missing = int(missing_mask_all.sum())\n",
    "    missing_pct = 100.0 * num_missing / total_entries\n",
    "\n",
    "    valid_mask_all = ~missing_mask_all\n",
    "    if np.any(valid_mask_all):\n",
    "        ae_valid = np.sqrt(mse_matrix[valid_mask_all].astype(np.float32))\n",
    "\n",
    "        mae_global = float(ae_valid.mean())\n",
    "        rmse_global = float(np.sqrt(mse_matrix[valid_mask_all].astype(np.float32).mean()))\n",
    "        median_ae = float(np.median(ae_valid))\n",
    "        p95_ae = float(np.percentile(ae_valid, 95))\n",
    "\n",
    "        dataset_mse_global = float(mse_matrix[valid_mask_all].astype(np.float32).mean())\n",
    "    else:\n",
    "        mae_global = rmse_global = median_ae = p95_ae = np.nan\n",
    "        dataset_mse_global = np.nan\n",
    "\n",
    "    print(f\"✅ MSE global: {dataset_mse_global:.6f}\")\n",
    "    print(f\"✅ MAE: {mae_global:.6f} | RMSE: {rmse_global:.6f} | Median AE: {median_ae:.6f} | P95 AE: {p95_ae:.6f}\")\n",
    "    print(f\"✅ Missing: {missing_pct:.2f}%\")\n",
    "\n",
    "    max_points_for_plot = 2_000_000\n",
    "    ae_for_plot = ae_valid\n",
    "    if ae_for_plot.size > max_points_for_plot:\n",
    "        idx = np.random.choice(ae_for_plot.size, size=max_points_for_plot, replace=False)\n",
    "        ae_for_plot = ae_for_plot[idx]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(ae_for_plot, bins=100)  \n",
    "    plt.xlabel(\"Absolute Error\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Abs Error Distribution – {dataset_name}\")\n",
    "    plot_path = os.path.join(dataset_output_dir, f\"{dataset_name}_abs_error_hist.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved plot: {plot_path}\")\n",
    "\n",
    "    mse_npy_path = os.path.join(dataset_output_dir, f\"{dataset_name}_mse_per_sample_per_position.npy\")\n",
    "    np.save(mse_npy_path, mse_matrix)\n",
    "    print(f\"Saved: {mse_npy_path}\")\n",
    "\n",
    "    summary_row = {\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Missing_Pct\": missing_pct,\n",
    "        \"MSE_Global\": dataset_mse_global,\n",
    "        \"MAE_Global\": mae_global,\n",
    "        \"RMSE_Global\": rmse_global,\n",
    "        \"Median_AE\": median_ae,\n",
    "        \"P95_AE\": p95_ae,\n",
    "        **{f\"MSE_Segment_{i+1}\": segment_mse_avgs[i] for i in range(num_segments)}\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame([summary_row])\n",
    "    summary_csv_path = os.path.join(dataset_output_dir, f\"{dataset_name}_mse_summary.csv\")\n",
    "    summary_df.to_csv(summary_csv_path, index=False)\n",
    "    print(f\"Saved: {summary_csv_path}\")\n",
    "\n",
    "    info_copy_path = os.path.join(dataset_output_dir, \"model_info.txt\")\n",
    "    with open(info_copy_path, \"w\") as f:\n",
    "        f.writelines([line + (\"\\n\" if not line.endswith(\"\\n\") else \"\") for line in info_lines])\n",
    "    print(f\"Saved: {info_copy_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f642c-a42c-4455-9cca-bf6635a50ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
