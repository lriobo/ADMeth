{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5e6f45-e08c-461b-bd47-b6b9689a996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "283b6335-c859-4d5c-94f4-86ef1e1cf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONFIGURACIÓN ====\n",
    "model_dir = \"/home/77462217B/lois/ADMeth/model/gridsearchmodelwomasklight22K\"\n",
    "datasets = [\n",
    "    \"/home/77462217B/lois/ADMeth/data/ValidateDataset5K_float16.npy\",\n",
    "    \"/home/77462217B/lois/ADMeth/data/datasets/Michaud_float16.npy\",\n",
    "    \"/home/77462217B/lois/ADMeth/data/datasets/FraCon_float16.npy\",\n",
    "    \"/home/77462217B/lois/ADMeth/data/datasets/FraCas_float16.npy\"\n",
    "]\n",
    "\n",
    "output_base_dir = \"/home/77462217B/lois/ADMeth/outcomes/griddatasetv2outcomes/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df1f7850-9869-49ed-8b49-f7b2249a1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración leída del modelo: Dropout=False, BatchNorm=True, Segment size=10000\n"
     ]
    }
   ],
   "source": [
    "# ==== LEER CONFIGURACIÓN DEL MODELO ====\n",
    "info_path = os.path.join(model_dir, \"model_info.txt\")\n",
    "if not os.path.exists(info_path):\n",
    "    raise FileNotFoundError(f\"No se encontró model_info.txt en {model_dir}\")\n",
    "\n",
    "with open(info_path, \"r\") as f:\n",
    "    info_lines = f.readlines()\n",
    "\n",
    "# Parsear info\n",
    "info_dict = {}\n",
    "for line in info_lines:\n",
    "    key, value = line.strip().split(\":\", 1)\n",
    "    info_dict[key.strip()] = value.strip()\n",
    "\n",
    "dense_layers = ast.literal_eval(info_dict[\"Dense layers\"])\n",
    "latent_dim = int(info_dict[\"Latent dimensions\"])\n",
    "use_dropout = info_dict[\"Dropout\"].lower() == \"true\"\n",
    "use_batchnorm = info_dict[\"BatchNorm\"].lower() == \"true\"\n",
    "\n",
    "segment_size = 10000\n",
    "print(f\"Configuración leída del modelo: Dropout={use_dropout}, BatchNorm={use_batchnorm}, Segment size={segment_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf2eef75-d586-4cf9-b657-4432d78d51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DEFINICIÓN DEL MODELO ====\n",
    "class SegmentAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, use_dropout, use_batchnorm):\n",
    "        super().__init__()\n",
    "        layers_enc = [nn.Linear(input_size, dense_layers[0]), nn.ReLU()]\n",
    "        if use_batchnorm: layers_enc.append(nn.BatchNorm1d(dense_layers[0]))\n",
    "        if use_dropout: layers_enc.append(nn.Dropout(0.2))\n",
    "        layers_enc.append(nn.Linear(dense_layers[0], latent_size))\n",
    "        layers_enc.append(nn.ReLU())\n",
    "        if use_batchnorm: layers_enc.append(nn.BatchNorm1d(latent_size))\n",
    "        if use_dropout: layers_enc.append(nn.Dropout(0.2))\n",
    "\n",
    "        layers_dec = [nn.Linear(latent_size, dense_layers[2]), nn.ReLU()]\n",
    "        if use_batchnorm: layers_dec.append(nn.BatchNorm1d(dense_layers[2]))\n",
    "        if use_dropout: layers_dec.append(nn.Dropout(0.2))\n",
    "        layers_dec.append(nn.Linear(dense_layers[2], input_size))\n",
    "        layers_dec.append(nn.Sigmoid())\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers_enc)\n",
    "        self.decoder = nn.Sequential(*layers_dec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c930968-5d7b-4c91-9280-6188385599cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 32 modelos de segmentos.\n"
     ]
    }
   ],
   "source": [
    "# ==== LISTAR MODELOS ORDENADOS ====\n",
    "model_files = sorted(\n",
    "    [f for f in os.listdir(model_dir) if f.startswith(\"autoencoder_segment_\") and f.endswith(\".pth\")],\n",
    "    key=lambda x: int(re.search(r\"_(\\d+)\\.pth\", x).group(1))\n",
    ")\n",
    "\n",
    "num_segments = len(model_files)\n",
    "print(f\"Se encontraron {num_segments} modelos de segmentos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "579557af-00ed-4209-8173-6856676ef43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Evaluando dataset: ValidateDataset5K_float16\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SegmentAutoencoder:\n\tMissing key(s) in state_dict: \"encoder.3.weight\", \"encoder.3.bias\", \"encoder.5.weight\", \"encoder.5.bias\", \"encoder.5.running_mean\", \"encoder.5.running_var\", \"decoder.3.weight\", \"decoder.3.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.6.weight\", \"encoder.6.bias\", \"encoder.6.running_mean\", \"encoder.6.running_var\", \"encoder.6.num_batches_tracked\", \"encoder.4.weight\", \"encoder.4.bias\", \"decoder.4.weight\", \"decoder.4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# ==== Cargar el modelo del segmento ====\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         model \u001b[38;5;241m=\u001b[39m SegmentAutoencoder(segment_size, latent_dim, use_dropout, use_batchnorm)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 26\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# ==== Predicciones y cálculo de MSE por posición ====\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#        with torch.no_grad():\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#            X_tensor = torch.tensor(X_segment, device=device, dtype=torch.float32)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#            segment_mse_avgs.append(mse_per_position.mean())\u001b[39;00m\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;66;03m# ==== Predicciones y cálculo de MSE por posición (ignorando ceros como missing) ====\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SegmentAutoencoder:\n\tMissing key(s) in state_dict: \"encoder.3.weight\", \"encoder.3.bias\", \"encoder.5.weight\", \"encoder.5.bias\", \"encoder.5.running_mean\", \"encoder.5.running_var\", \"decoder.3.weight\", \"decoder.3.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.6.weight\", \"encoder.6.bias\", \"encoder.6.running_mean\", \"encoder.6.running_var\", \"encoder.6.num_batches_tracked\", \"encoder.4.weight\", \"encoder.4.bias\", \"decoder.4.weight\", \"decoder.4.bias\". "
     ]
    }
   ],
   "source": [
    "# ==== EVALUAR ====\n",
    "for dataset_path in datasets:\n",
    "    dataset_name = os.path.splitext(os.path.basename(dataset_path))[0]\n",
    "\n",
    "    # Crear carpeta específica para este dataset\n",
    "    dataset_output_dir = os.path.join(output_base_dir, dataset_name)\n",
    "    os.makedirs(dataset_output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n→ Evaluando dataset: {dataset_name}\")\n",
    "    X_data = np.load(dataset_path).astype(np.float16).T\n",
    "    n_samples, total_features = X_data.shape\n",
    "    expected_features = 320000\n",
    "    assert total_features == expected_features, f\"{dataset_path} tiene {total_features} columnas, se esperaban {expected_features}\"\n",
    "\n",
    "    mse_matrix = np.zeros((n_samples, total_features), dtype=np.float16)\n",
    "    segment_mse_avgs = []\n",
    "\n",
    "    for idx, model_file in enumerate(model_files):\n",
    "        # ==== Seleccionar el segmento correspondiente ====\n",
    "        start = idx * segment_size\n",
    "        end = start + segment_size\n",
    "        X_segment = X_data[:, start:end]  # <-- División en segmentos\n",
    "    \n",
    "        # ==== Cargar el modelo del segmento ====\n",
    "        model = SegmentAutoencoder(segment_size, latent_dim, use_dropout, use_batchnorm).to(device)\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, model_file), map_location=device))\n",
    "        model.eval()\n",
    "    \n",
    "        # ==== Predicciones y cálculo de MSE por posición ====\n",
    "#        with torch.no_grad():\n",
    "#            X_tensor = torch.tensor(X_segment, device=device, dtype=torch.float32)\n",
    "#            preds = model(X_tensor).cpu().numpy()\n",
    "#            mse_per_position = (preds - X_segment) ** 2\n",
    "#            mse_matrix[:, start:end] = mse_per_position\n",
    "#            segment_mse_avgs.append(mse_per_position.mean())\n",
    "            # ==== Predicciones y cálculo de MSE por posición (ignorando ceros como missing) ====\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_segment, device=device, dtype=torch.float32)\n",
    "            preds = model(X_tensor).cpu().numpy().astype(np.float16)\n",
    "    \n",
    "        X_seg32 = X_segment.astype(np.float32)\n",
    "        mse_per_position = (preds - X_seg32) ** 2\n",
    "    \n",
    "        # Máscara de missing (valor original exactamente 0)\n",
    "        missing_mask = (X_segment == 0)\n",
    "    \n",
    "        # Ponemos -1 en las posiciones missing en la matriz de salida\n",
    "        mse_per_position[missing_mask] = -1.0\n",
    "    \n",
    "        # Guardamos en la matriz global\n",
    "        mse_matrix[:, start:end] = mse_per_position.astype(np.float16)\n",
    "    \n",
    "        # Media del segmento sin contar missing\n",
    "        valid_mask = ~missing_mask\n",
    "        if np.any(valid_mask):\n",
    "            seg_mean = mse_per_position[valid_mask].mean()\n",
    "        else:\n",
    "            seg_mean = np.nan\n",
    "        segment_mse_avgs.append(seg_mean)\n",
    "\n",
    "\n",
    "\n",
    "    # ==== MÉTRICAS GLOBALES (ignorando missings) ====\n",
    "    missing_mask_all = (mse_matrix == -1)\n",
    "    total_entries = mse_matrix.size\n",
    "    num_missing = int(missing_mask_all.sum())\n",
    "    missing_pct = 100.0 * num_missing / total_entries\n",
    "    \n",
    "    valid_mask_all = ~missing_mask_all\n",
    "    if np.any(valid_mask_all):\n",
    "        # AE = |pred - true| = sqrt(MSE por posición)\n",
    "        ae_valid = np.sqrt(mse_matrix[valid_mask_all].astype(np.float32))\n",
    "    \n",
    "        mae_global = float(ae_valid.mean())\n",
    "        rmse_global = float(np.sqrt(mse_matrix[valid_mask_all].astype(np.float32).mean()))\n",
    "        median_ae = float(np.median(ae_valid))\n",
    "        p95_ae = float(np.percentile(ae_valid, 95))\n",
    "    \n",
    "        # MSE global (por si lo seguías guardando)\n",
    "        dataset_mse_global = float(mse_matrix[valid_mask_all].astype(np.float32).mean())\n",
    "    else:\n",
    "        mae_global = rmse_global = median_ae = p95_ae = np.nan\n",
    "        dataset_mse_global = np.nan\n",
    "    \n",
    "    print(f\"✅ MSE global: {dataset_mse_global:.6f}\")\n",
    "    print(f\"✅ MAE: {mae_global:.6f} | RMSE: {rmse_global:.6f} | Mediana AE: {median_ae:.6f} | P95 AE: {p95_ae:.6f}\")\n",
    "    print(f\"✅ Missing: {missing_pct:.2f}%\")\n",
    "    \n",
    "    # ==== PLOT DISTRIBUCIÓN DE ERRORES ABSOLUTOS ====\n",
    "    max_points_for_plot = 2_000_000\n",
    "    ae_for_plot = ae_valid\n",
    "    if ae_for_plot.size > max_points_for_plot:\n",
    "        idx = np.random.choice(ae_for_plot.size, size=max_points_for_plot, replace=False)\n",
    "        ae_for_plot = ae_for_plot[idx]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(ae_for_plot, bins=100)\n",
    "    plt.xlabel(\"Absolute Error\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Abs Error Distribution – {dataset_name}\")\n",
    "    plot_path = os.path.join(dataset_output_dir, f\"{dataset_name}_abs_error_hist.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Guardado plot: {plot_path}\")\n",
    "\n",
    "\n",
    "    # ==== GUARDAR MATRIZ COMPLETA ====\n",
    "    mse_npy_path = os.path.join(dataset_output_dir, f\"{dataset_name}_mse_per_sample_per_position.npy\")\n",
    "    np.save(mse_npy_path, mse_matrix)\n",
    "    print(f\"Guardado: {mse_npy_path}\")\n",
    "\n",
    "    # ==== GUARDAR RESUMEN ====\n",
    "    summary_row = {\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Missing_Pct\": missing_pct,\n",
    "        \"MSE_Global\": dataset_mse_global,\n",
    "        \"MAE_Global\": mae_global,\n",
    "        \"RMSE_Global\": rmse_global,\n",
    "        \"Median_AE\": median_ae,\n",
    "        \"P95_AE\": p95_ae,\n",
    "        **{f\"MSE_Segment_{i+1}\": segment_mse_avgs[i] for i in range(num_segments)}\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame([summary_row])\n",
    "    summary_csv_path = os.path.join(dataset_output_dir, f\"{dataset_name}_mse_summary.csv\")\n",
    "    summary_df.to_csv(summary_csv_path, index=False)\n",
    "    print(f\"Guardado: {summary_csv_path}\")\n",
    "\n",
    "    # ==== GUARDAR CONFIGURACIÓN DEL MODELO ====\n",
    "    info_copy_path = os.path.join(dataset_output_dir, \"model_info.txt\")\n",
    "    with open(info_copy_path, \"w\") as f:\n",
    "        f.writelines(info_lines)\n",
    "    print(f\"Guardado: {info_copy_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799157e6-165b-44a7-b6a0-e92a20dc2272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ede2be-d392-4b8f-8430-72f60cc9276c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
